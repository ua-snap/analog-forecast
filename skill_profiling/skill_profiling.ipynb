{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6cca42-2b7d-417e-885e-3840ba8e66e2",
   "metadata": {},
   "source": [
    "# Skill profiling\n",
    "\n",
    "This notebook will orchestrate a skill profiling of the analog forecast across all available options for a set of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62333829-afdb-4bd3-b5f8-010f409e6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import luts\n",
    "from config import data_dir, project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f178d579-7e21-4ccb-934f-fe820ffe434e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Goal\n",
    "\n",
    "The goal is to compute the error for the analog forecast method and a naive forecast method, for 50 dates. For now, those dates will be randomly chosen, but this workflow may be adapted to accept user supplied dates. The product here should be a table of results - errors between the forecast and \"observed\" values.\n",
    "\n",
    "Some facts:\n",
    "\n",
    "* forecasts will be made for the 14 days post-reference date\n",
    "* forecasts will use 5 analogs\n",
    "* a forecast for a given date is the mean of the corresponding subsequent dates across all analogs\n",
    "* we are not mixing variables or spatial domains or weighting\n",
    "\n",
    "### Processing strategy\n",
    "\n",
    "We have some large data files - daily data for the northern hemisphere for our variables of interest - that will end up being read completely into memory because of the search of analogs over the entire time series. Additionally, the naive forecasting will be sampling many of the time steps. Being ~45GB (or ~23GB for the raw (i.e. non-anomaly-based) files), it will make sense to read the dataset completely into memory and then iterate over the possible groups. So we will iterate over the data files at the lowest level, which are grouped by variable and data type (raw vs anomaly).\n",
    "\n",
    "### Naive profiling\n",
    "\n",
    "I believe we only need to simulate the naive forecasts for each domain and variable, not for every reference date. This assumes that the distribution of \"skill\" (RMSE for now) for the naive forecast is the same for every day of the year. For each spatial domain and variable, we are attempting to simulate the distribution of a naive forecast skill based on selecting uniformly random analogs from the complete historical time series. \n",
    "\n",
    "So, we can create a table of naive forecast skill for all combinations of spatial domain and variable, which can then be joined with a table of analog forecast results for useful comparisons. \n",
    "\n",
    "We will use slurm for this because each group takes a while to process. We will call the `run_profile.py` script to the profiling for a particular variable and data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e83f3ac-9fee-499b-856a-da96d35b6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_run_profile_sbatch(sbatch_fp, varname, results_fp, use_anom, data_dir, project_dir):\n",
    "    sbatch_head = (\n",
    "        \"#!/bin/sh\\n\"\n",
    "        \"#SBATCH --nodes=1\\n\"\n",
    "        \"#SBATCH --cpus-per-task=32\\n\"\n",
    "        \"#SBATCH --mail-type=FAIL\\n\"\n",
    "        f\"#SBATCH --mail-user=kmredilla@alaska.edu\\n\"\n",
    "        f\"#SBATCH -p main\\n\"\n",
    "        \"conda activate analog-forecast\\n\"\n",
    "        f\"export DATA_DIR={data_dir}\\n\"\n",
    "        f\"export PROJECT_DIR={project_dir}\\n\"\n",
    "    )\n",
    "\n",
    "    py_commands = (\n",
    "        f\"time python {project_dir.joinpath('skill_profiling', 'run_profile.py')} \"\n",
    "        f\"--varname {varname} \"\n",
    "        f\"--results_file {results_fp} \"\n",
    "        f\"{'-a' if use_anom else ''} \"\n",
    "    )\n",
    "\n",
    "    commands = sbatch_head + py_commands\n",
    "\n",
    "    with open(sbatch_fp, \"w\") as f:\n",
    "        f.write(commands)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488c419-79c6-49de-b2ba-92ce1d5e678e",
   "metadata": {},
   "source": [
    "Make the slurm scripts for `sbatch`ing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6ea44b-35bb-4e90-9eea-ff034ca2039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_dir = Path(\"slurm\")\n",
    "sbatch_dir.mkdir(exist_ok=True)\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "sbatch_fps = []\n",
    "results_fps = []\n",
    "\n",
    "for varname in luts.varnames_lu.keys():\n",
    "    for use_anom in [True, False]:\n",
    "        group_str = f\"{varname}{'_anom' if use_anom else ''}\"\n",
    "        sbatch_fp = sbatch_dir.joinpath(f\"run_profile_{group_str}.slurm\").resolve()\n",
    "        results_fp = results_dir.joinpath(f\"{group_str}.csv\").resolve()\n",
    "        sbatch_kwargs = {\n",
    "            \"sbatch_fp\": sbatch_fp,\n",
    "            \"varname\": varname,\n",
    "            \"results_fp\": results_fp,\n",
    "            \"use_anom\": use_anom,\n",
    "            \"data_dir\": data_dir,\n",
    "            \"project_dir\": project_dir,\n",
    "        }\n",
    "        \n",
    "        write_run_profile_sbatch(**sbatch_kwargs)\n",
    "        sbatch_fps.append(sbatch_fps)\n",
    "        results_fps.append(results_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc5ad7-2f60-4044-82c7-19f114796fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
