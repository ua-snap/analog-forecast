{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9361fc-03c8-45ef-93f7-a4b0080ddef3",
   "metadata": {},
   "source": [
    "# Profiling for dates associated with Nome storms\n",
    "\n",
    "This notebook is for visualizing and analsing the results from profiling the analog forecast method using dates where Nome, AK was hit by a storm (provided by collaborators). \n",
    "\n",
    "\n",
    "The dates provided will be referred to as the \"dates of interest.\" We applied the skill profiling framework for the the third and fifth days preceding to the dates of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6fe691b-a48a-4d5b-9d33-68562bb821ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "# local\n",
    "import luts\n",
    "from config import data_dir\n",
    "import analog_forecast as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0c00b-14bb-40f1-a0e4-b2c50a926fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a09c89-0c53-4667-ba42-7296fd519fab",
   "metadata": {},
   "source": [
    "Concatenate the results into single tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde0a11c-b43f-4bae-a813-f1764b82677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_df = pd.concat([pd.read_csv(fp) for fp in Path(\"results\").glob(\"*.csv\") if \"naive\" not in fp.name])\n",
    "naive_df = pd.concat([pd.read_csv(fp) for fp in Path(\"results\").glob(\"*naive.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fb6ed-4db8-43dc-a9b1-2959daf53505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24349cf3-349e-4992-b3d8-45d0eb764a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2097eea8-486e-4148-be22-61353faeea32",
   "metadata": {},
   "source": [
    "## QC\n",
    "\n",
    "First, some validation just to make sure we have things straight here. Let's take the first and last row here and manually check each aspect of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160a6df5-c3a7-4a73-b4ac-d85e5a413548",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = analog_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e2359-3bbe-4c7d-ad76-295b4b15bd33",
   "metadata": {},
   "source": [
    "Load the ERA5 data that we will use to search and generate forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f96cb01-004f-4398-84fc-631692a490ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable                      t2m\n",
       "spatial_domain             alaska\n",
       "anomaly_search               True\n",
       "reference_date         2004-10-08\n",
       "forecast_day_number             1\n",
       "forecast_error              4.851\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586fad43-bac4-40af-8373-09e68fd5fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = row[\"variable\"]\n",
    "ref_date = row[\"reference_date\"]\n",
    "ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"anom_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb3b80-ef0a-44b9-b3b5-4f087c811aa2",
   "metadata": {},
   "source": [
    "Subset to the spatial domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7a893c-171a-47f3-9b6e-73cab8356b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (23011, 361, 1440)\n",
      "Shape after spatial subset: (23011, 129, 221)\n"
     ]
    }
   ],
   "source": [
    "spatial_domain = row[\"spatial_domain\"]\n",
    "bbox = luts.spatial_domains[spatial_domain][\"bbox\"]\n",
    "sub_da = ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "print(\"Original shape:\", ds[varname].shape)\n",
    "print(\"Shape after spatial subset:\", sub_da.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765dacc-c94e-43f8-accf-dcb4f6c661a5",
   "metadata": {},
   "source": [
    "Compute RMSE for all time slices before and after the reference date and forecast window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1908fd52-08d4-4c63-89fa-7922c5a4509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 5.63 s, total: 8.72 s\n",
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analogs = af.find_analogs(sub_da, ref_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d96da2-e6a7-4ee0-aa29-5d988eeaac42",
   "metadata": {},
   "source": [
    "Load the raw value version for generating and checking the forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b07d59e-e97b-4684-a8c2-dcc3079b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 50.8 s, total: 1min 47s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9350772-6493-4d7f-8914-709f2f236a49",
   "metadata": {},
   "source": [
    "Subset the raw data spatially and compute the forecast as the mean of the arrays for day t+1 for each of the analogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156cda48-7379-4a99-a6ba-0ac57389358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sub_da = raw_ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "forecast = (raw_sub_da.sel(time=analogs.time.values + pd.to_timedelta(1, \"d\")).values).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a323a-0fbf-4197-97c6-dbd7f0deb5dc",
   "metadata": {},
   "source": [
    "Compute the RMSE between forecast and the date after the reference date, and cross check with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2415e53c-ea8f-4229-b6b6-34d3e7eb97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(\n",
    "    ((raw_sub_da.sel(\n",
    "        time=pd.to_datetime(ref_date + \" 12:00:00\") + pd.to_timedelta(1, \"d\")\n",
    "    ) - forecast) ** 2).mean()\n",
    ").round(3)\n",
    "\n",
    "assert test_rmse == row[\"forecast_error\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5c15d-e1ef-4d2f-92ea-00f0308a81ee",
   "metadata": {},
   "source": [
    "Make sure memory is freed up for loading different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c9c5b58-d9b9-4882-a7fd-1abf85f683dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del ds\n",
    "    del raw_sub_da\n",
    "    del raw_ds\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa06a0-3bd4-459d-8a87-1658b0e24d47",
   "metadata": {},
   "source": [
    "Do the same as above for another row with a different variable, spatial domain, etc. Also with a different forecast day number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5a101e-60d9-4b64-8937-9fa936481f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (23011, 361, 1440)\n",
      "Shape after spatial subset: (23011, 361, 240)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ensure it is a different variable\n",
    "row = analog_df.query(\"variable == 'sst'\").iloc[-1]\n",
    "varname = row[\"variable\"]\n",
    "ref_date = row[\"reference_date\"]\n",
    "spatial_domain = row[\"spatial_domain\"]\n",
    "bbox = luts.spatial_domains[spatial_domain][\"bbox\"]\n",
    "ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"filename\"]))\n",
    "sub_da = ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "print(\"Original shape:\", ds[varname].shape)\n",
    "print(\"Shape after spatial subset:\", sub_da.shape)\n",
    "analogs = af.find_analogs(sub_da, ref_date)\n",
    "date_offset = row[\"forecast_day_number\"]\n",
    "forecast = (sub_da.sel(time=analogs.time.values + pd.to_timedelta(date_offset, \"d\")).values).mean(axis=0)\n",
    "test_rmse = np.sqrt(\n",
    "    ((sub_da.sel(\n",
    "        time=pd.to_datetime(ref_date + \" 12:00:00\") + pd.to_timedelta(date_offset, \"d\")\n",
    "    ) - forecast) ** 2).mean()\n",
    ").round(3)\n",
    "\n",
    "assert test_rmse == row[\"forecast_error\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44730a2b-d15d-4cde-b805-0e94cd5720dc",
   "metadata": {},
   "source": [
    "## Save tables\n",
    "\n",
    "Save the combined tables for collaborators to have a look at.\n",
    "\n",
    "Make a table with the forecast date included and limit to those particular dates provided by partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f815e8c9-438f-4816-882c-6c20a8a770cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>spatial_domain</th>\n",
       "      <th>anomaly_search</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>forecast_day_number</th>\n",
       "      <th>forecast_error</th>\n",
       "      <th>forecast_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2m</td>\n",
       "      <td>alaska</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-10-08</td>\n",
       "      <td>3</td>\n",
       "      <td>6.213</td>\n",
       "      <td>2004-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t2m</td>\n",
       "      <td>alaska</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-10-15</td>\n",
       "      <td>3</td>\n",
       "      <td>4.711</td>\n",
       "      <td>2004-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t2m</td>\n",
       "      <td>alaska</td>\n",
       "      <td>True</td>\n",
       "      <td>2005-09-19</td>\n",
       "      <td>3</td>\n",
       "      <td>3.814</td>\n",
       "      <td>2005-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>t2m</td>\n",
       "      <td>alaska</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>3</td>\n",
       "      <td>5.250</td>\n",
       "      <td>2013-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>t2m</td>\n",
       "      <td>alaska</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-05-06</td>\n",
       "      <td>3</td>\n",
       "      <td>4.350</td>\n",
       "      <td>2004-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>t2m</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-09-17</td>\n",
       "      <td>5</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2005-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>t2m</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>False</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3.781</td>\n",
       "      <td>2013-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>t2m</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>False</td>\n",
       "      <td>2004-05-04</td>\n",
       "      <td>5</td>\n",
       "      <td>2.078</td>\n",
       "      <td>2004-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>t2m</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>5</td>\n",
       "      <td>3.106</td>\n",
       "      <td>2015-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>t2m</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>5</td>\n",
       "      <td>3.989</td>\n",
       "      <td>2015-11-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable spatial_domain  anomaly_search reference_date  \\\n",
       "2        t2m         alaska            True     2004-10-08   \n",
       "16       t2m         alaska            True     2004-10-15   \n",
       "30       t2m         alaska            True     2005-09-19   \n",
       "44       t2m         alaska            True     2013-11-03   \n",
       "58       t2m         alaska            True     2004-05-06   \n",
       "..       ...            ...             ...            ...   \n",
       "718      t2m  north_pacific           False     2005-09-17   \n",
       "732      t2m  north_pacific           False     2013-11-01   \n",
       "746      t2m  north_pacific           False     2004-05-04   \n",
       "760      t2m  north_pacific           False     2015-11-04   \n",
       "774      t2m  north_pacific           False     2015-11-18   \n",
       "\n",
       "     forecast_day_number  forecast_error forecast_date  \n",
       "2                      3           6.213    2004-10-11  \n",
       "16                     3           4.711    2004-10-18  \n",
       "30                     3           3.814    2005-09-22  \n",
       "44                     3           5.250    2013-11-06  \n",
       "58                     3           4.350    2004-05-09  \n",
       "..                   ...             ...           ...  \n",
       "718                    5           2.281    2005-09-22  \n",
       "732                    5           3.781    2013-11-06  \n",
       "746                    5           2.078    2004-05-09  \n",
       "760                    5           3.106    2015-11-09  \n",
       "774                    5           3.989    2015-11-23  \n",
       "\n",
       "[448 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dates = [\"2004-10-11\", \"2004-10-18\", \"2005-09-22\", \"2013-11-06\", \"2004-05-09\", \"2015-11-09\", \"2015-11-23\"]\n",
    "\n",
    "analog_df[\"forecast_date\"] = (pd.to_datetime(analog_df[\"reference_date\"]) + pd.to_timedelta(analog_df[\"forecast_day_number\"], unit=\"d\"))\n",
    "analog_df.query(\"forecast_date in @ref_dates & forecast_day_number in [3, 5]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8bc4f-f7ee-4e0e-9ff9-3a0ba248c99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
