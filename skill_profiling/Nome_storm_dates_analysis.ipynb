{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9361fc-03c8-45ef-93f7-a4b0080ddef3",
   "metadata": {},
   "source": [
    "# Profiling for dates associated with Nome storms\n",
    "\n",
    "This notebook is for visualizing and analsing the results from profiling the analog forecast method using dates where Nome, AK was hit by a storm (provided by collaborators). \n",
    "\n",
    "\n",
    "The dates provided will be referred to as the \"dates of interest.\" We applied the skill profiling framework for the the third and fifth days preceding to the dates of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6fe691b-a48a-4d5b-9d33-68562bb821ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "# local\n",
    "import luts\n",
    "from config import data_dir\n",
    "import analog_forecast as af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a09c89-0c53-4667-ba42-7296fd519fab",
   "metadata": {},
   "source": [
    "Concatenate the results into single tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde0a11c-b43f-4bae-a813-f1764b82677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_df = pd.concat([pd.read_csv(fp) for fp in Path(\"results\").glob(\"*.csv\") if \"naive\" not in fp.name])\n",
    "naive_df = pd.concat([pd.read_csv(fp) for fp in Path(\"results\").glob(\"*naive.csv\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097eea8-486e-4148-be22-61353faeea32",
   "metadata": {},
   "source": [
    "## QC\n",
    "\n",
    "First, some validation just to make sure we have things straight here. Let's take the first and last row here and manually check each aspect of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160a6df5-c3a7-4a73-b4ac-d85e5a413548",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = analog_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e2359-3bbe-4c7d-ad76-295b4b15bd33",
   "metadata": {},
   "source": [
    "Load the ERA5 data that we will use to search and generate forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f96cb01-004f-4398-84fc-631692a490ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable                      t2m\n",
       "spatial_domain             alaska\n",
       "anomaly_search               True\n",
       "reference_date         2004-10-08\n",
       "forecast_day_number             1\n",
       "forecast_error              4.851\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586fad43-bac4-40af-8373-09e68fd5fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = row[\"variable\"]\n",
    "ref_date = row[\"reference_date\"]\n",
    "ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"anom_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb3b80-ef0a-44b9-b3b5-4f087c811aa2",
   "metadata": {},
   "source": [
    "Subset to the spatial domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7a893c-171a-47f3-9b6e-73cab8356b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (23011, 361, 1440)\n",
      "Shape after spatial subset: (23011, 129, 221)\n"
     ]
    }
   ],
   "source": [
    "spatial_domain = row[\"spatial_domain\"]\n",
    "bbox = luts.spatial_domains[spatial_domain][\"bbox\"]\n",
    "sub_da = ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "print(\"Original shape:\", ds[varname].shape)\n",
    "print(\"Shape after spatial subset:\", sub_da.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765dacc-c94e-43f8-accf-dcb4f6c661a5",
   "metadata": {},
   "source": [
    "Compute RMSE for all time slices before and after the reference date and forecast window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1908fd52-08d4-4c63-89fa-7922c5a4509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 3.6 s, total: 8.04 s\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analogs = af.find_analogs(sub_da, ref_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d96da2-e6a7-4ee0-aa29-5d988eeaac42",
   "metadata": {},
   "source": [
    "Load the raw value version for generating and checking the forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b07d59e-e97b-4684-a8c2-dcc3079b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1min 6s, total: 2min 8s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9350772-6493-4d7f-8914-709f2f236a49",
   "metadata": {},
   "source": [
    "Subset the raw data spatially and compute the forecast as the mean of the arrays for day t+1 for each of the analogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156cda48-7379-4a99-a6ba-0ac57389358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sub_da = raw_ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "forecast = (raw_sub_da.sel(time=analogs.time.values + pd.to_timedelta(1, \"d\")).values).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a323a-0fbf-4197-97c6-dbd7f0deb5dc",
   "metadata": {},
   "source": [
    "Compute the RMSE between forecast and the date after the reference date, and cross check with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2415e53c-ea8f-4229-b6b6-34d3e7eb97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(\n",
    "    ((raw_sub_da.sel(\n",
    "        time=pd.to_datetime(ref_date + \" 12:00:00\") + pd.to_timedelta(1, \"d\")\n",
    "    ) - forecast) ** 2).mean()\n",
    ").round(3)\n",
    "\n",
    "assert test_rmse == row[\"forecast_error\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5c15d-e1ef-4d2f-92ea-00f0308a81ee",
   "metadata": {},
   "source": [
    "Make sure memory is freed up for loading different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9c5b58-d9b9-4882-a7fd-1abf85f683dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "try:\n",
    "    del ds\n",
    "    del sub_da\n",
    "    del raw_sub_da\n",
    "    del raw_ds\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa06a0-3bd4-459d-8a87-1658b0e24d47",
   "metadata": {},
   "source": [
    "Do the same as above for another row with a different variable, spatial domain, etc. Also with a different forecast day number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5a101e-60d9-4b64-8937-9fa936481f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (23011, 361, 1440)\n",
      "Shape after spatial subset: (23011, 361, 240)\n",
      "CPU times: user 1min 16s, sys: 1min 26s, total: 2min 43s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ensure it is a different variable\n",
    "row = analog_df.query(\"variable == 'sst'\").iloc[-1]\n",
    "varname = row[\"variable\"]\n",
    "ref_date = row[\"reference_date\"]\n",
    "spatial_domain = row[\"spatial_domain\"]\n",
    "bbox = luts.spatial_domains[spatial_domain][\"bbox\"]\n",
    "ds = xr.load_dataset(data_dir.joinpath(luts.varnames_lu[varname][\"filename\"]))\n",
    "sub_da = ds[varname].sel(latitude=slice(bbox[3], bbox[1]), longitude=slice(bbox[0], bbox[2]))\n",
    "analogs = af.find_analogs(sub_da, ref_date)\n",
    "date_offset = row[\"forecast_day_number\"]\n",
    "forecast = (sub_da.sel(time=analogs.time.values + pd.to_timedelta(date_offset, \"d\")).values).mean(axis=0)\n",
    "test_rmse = np.sqrt(\n",
    "    ((sub_da.sel(\n",
    "        time=pd.to_datetime(ref_date + \" 12:00:00\") + pd.to_timedelta(date_offset, \"d\")\n",
    "    ) - forecast) ** 2).mean()\n",
    ").round(3)\n",
    "\n",
    "assert test_rmse == row[\"forecast_error\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44730a2b-d15d-4cde-b805-0e94cd5720dc",
   "metadata": {},
   "source": [
    "## Save tables\n",
    "\n",
    "Save the combined tables for collaborators to have a look at.\n",
    "\n",
    "Make a table with the forecast date included, and limit it to those particular dates provided by partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f815e8c9-438f-4816-882c-6c20a8a770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dates = [\"2004-10-11\", \"2004-10-18\", \"2005-09-22\", \"2013-11-06\", \"2004-05-09\", \"2015-11-09\", \"2015-11-23\"]\n",
    "\n",
    "analog_df[\"forecast_date\"] = (pd.to_datetime(analog_df[\"reference_date\"]) + pd.to_timedelta(analog_df[\"forecast_day_number\"], unit=\"d\"))\n",
    "analog_df.query(\"forecast_date in @ref_dates & forecast_day_number in [3, 5]\").to_csv(\"analog_profiling_results_Nome.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551f6a8-84c9-421b-ae91-b192644f7ab4",
   "metadata": {},
   "source": [
    "Also save a table of the naive forecast results subset to only days 3 and 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50c8bc4f-f7ee-4e0e-9ff9-3a0ba248c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_df.query(\"forecast_day_number in [3, 5]\").to_csv(\"naive_profiling_results_Nome.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffce13c-f7f8-4332-bc33-74f69c08ea8f",
   "metadata": {},
   "source": [
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
