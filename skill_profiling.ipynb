{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6cca42-2b7d-417e-885e-3840ba8e66e2",
   "metadata": {},
   "source": [
    "# Skill profiling\n",
    "\n",
    "This notebook will do some general skill profiling of the analog forecast.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963a5cea-8c29-4d2a-ac19-960cc66bf989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import tqdm\n",
    "# local\n",
    "from analog_forecast import find_analogs, read_subset_era5, make_forecast\n",
    "from config import data_dir\n",
    "import luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cc87ca-f77d-4205-b66b-578ce43e1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a dask cluster\n",
    "client = Client(n_workers=16, dashboard_address=\"localhost:33338\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca96ee32-dd3a-461f-94a4-bdc46fda9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose sample of random dates for simulating\n",
    "sub_da = read_subset_era5(\"alaska\", data_dir, \"t2m\", use_anom=False)\n",
    "ref_dates = np.random.choice(sub_da.time.values, 50, replace=False)\n",
    "ref_dates = [pd.to_datetime(d).strftime(\"%Y-%m-%d\") for d in ref_dates]\n",
    "\n",
    "varnames = list(luts.varnames_lu.keys())\n",
    "spatial_domains = list(luts.spatial_domains.keys())\n",
    "use_anom = [True, False]\n",
    "\n",
    "args = list(product(varnames, spatial_domains, ref_dates, use_anom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506fb2b2-d95e-49ea-933c-3094c89353ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_naive_timestamps(times, ref_date):\n",
    "    before_forecast = pd.date_range(\n",
    "        sub_da.time.values[0], \n",
    "        pd.to_datetime(ref_date + \" 12:00:00\") - pd.to_timedelta(1, unit=\"d\")\n",
    "    )\n",
    "    after_forecast = pd.date_range( \n",
    "        pd.to_datetime(ref_date + \" 12:00:00\") + pd.to_timedelta(15, unit=\"d\"),\n",
    "        times[-15]\n",
    "    )\n",
    "    times = np.concatenate([before_forecast, after_forecast])\n",
    "    \n",
    "    return times\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def forecast_and_error(sub_da, times, ref_date):\n",
    "    naive_forecast = make_forecast(sub_da, times, ref_date)\n",
    "    err = sub_da.sel(time=naive_forecast.time.values) - naive_forecast\n",
    "    return (err ** 2).mean(axis=(1, 2))\n",
    "\n",
    "\n",
    "def run_profile(varname, spatial_domain, ref_date, use_anom):\n",
    "    analogs = find_analogs(varname, ref_date, spatial_domain, data_dir, 16, use_anom)\n",
    "    sub_da = read_subset_era5(spatial_domain, data_dir, varname, use_anom=False)\n",
    "    forecast = make_forecast(sub_da, analogs.time.values, ref_date)\n",
    "    \n",
    "    possible_naive_times = get_possible_naive_timestamps(sub_da.time.values, ref_date)\n",
    "    # use dask delayed ot simulate 1000 naive forecasts\n",
    "    results = []\n",
    "    n = 500\n",
    "    for i in range(n):\n",
    "        times = np.random.choice(possible_naive_times, 5, replace=False)\n",
    "        sim_rmse = forecast_and_error(sub_da, times, ref_date)\n",
    "        results.append(sim_rmse)\n",
    "\n",
    "    sim_rmse = xr.concat(dask.compute(*results), pd.Index(range(n), name=\"sim\"))\n",
    "    analog_err = sub_da.sel(time=forecast.time.values) - forecast\n",
    "    \n",
    "    err_df = pd.DataFrame({\n",
    "        \"variable\": varname,\n",
    "        \"spatial_domain\": spatial_domain,\n",
    "        \"anomaly_search\": use_anom,\n",
    "        \"reference_date\": ref_date,\n",
    "        \"forecast_day_number\": np.arange(14) + 1,\n",
    "        \"analog\": (analog_err ** 2).mean(axis=(1, 2)).values,\n",
    "        \"naive_2.5\": sim_rmse.reduce(np.percentile, dim=\"sim\", q=2.5),\n",
    "        \"naive_97.5\": sim_rmse.reduce(np.percentile, dim=\"sim\", q=97.5),\n",
    "    })\n",
    "    \n",
    "    return err_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d9f55-9851-4332-b7c3-8fd81a0d789f",
   "metadata": {},
   "source": [
    "Run the simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb4d0b-ae89-4f48-a8b3-92563f87710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                          | 0/1600 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for arg in tqdm.tqdm(args):\n",
    "    results.append(run_profile(*arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224326a-f47b-4d64-a5d6-ecd4f1d2aca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
